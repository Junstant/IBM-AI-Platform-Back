# ğŸ“Š AI Platform Stats API

Sistema completo de mÃ©tricas y estadÃ­sticas para la plataforma IBM AI Backend.

## ğŸ¯ CaracterÃ­sticas Principales

### ğŸ” Middleware AutomÃ¡tico de MÃ©tricas
- âœ… **Intercepta TODAS las requests automÃ¡ticamente**
- âœ… **Logging automÃ¡tico** en `api_performance_logs`  
- âœ… **Tiempo de respuesta real** por endpoint
- âœ… **Status codes y errores** detallados
- âœ… **TamaÃ±o de request/response**
- âœ… **IP del cliente y User-Agent**
- âœ… **Request ID Ãºnico** para tracking

### ğŸ¥ Health Checks de Modelos IA
- âœ… **VerificaciÃ³n automÃ¡tica** cada 5 minutos
- âœ… **Estado de modelos** en `ai_models_metrics`
- âœ… **Ping a puertos** de Ollama/llama.cpp
- âœ… **Tiempo de respuesta** de modelos
- âœ… **DetecciÃ³n de modelos** caÃ­dos/cargando
- âœ… **Memoria/CPU usage** por modelo
- âœ… **Conteo de tokens** procesados

### ğŸ“Š MÃ©tricas de Performance por Funcionalidad
- âœ… **TextToSQL**: complejidad de query, tiempo SQL execution
- âœ… **Fraud Detection**: risk score, precisiÃ³n
- âœ… **Chatbot**: tokens usados, duraciÃ³n conversaciÃ³n
- âœ… **ActualizaciÃ³n en tiempo real** de `functionality_metrics`

### ğŸš¨ Sistema de Alertas AutomÃ¡tico
- âœ… **Modelos que no responden** > 30 segundos
- âœ… **APIs con error rate** > 10%
- âœ… **Memoria/CPU** > 90%
- âœ… **InserciÃ³n automÃ¡tica** en `system_alerts`
- âœ… **DetecciÃ³n proactiva** de problemas

### ğŸ¯ MÃ©tricas de PrecisiÃ³n/Calidad
- âœ… **TextToSQL**: validar sintaxis SQL generada
- âœ… **Fraud**: comparar con resultados esperados
- âœ… **ActualizaciÃ³n de** `accuracy_metrics` por modelo

### ğŸŒ APIs para Dashboard
```
GET /api/stats/dashboard-summary      # Resumen principal
GET /api/stats/models-status          # Estado de modelos
GET /api/stats/functionality-performance  # Performance por funcionalidad
GET /api/stats/recent-errors          # Errores recientes
GET /api/stats/hourly-trends          # Tendencias por hora
GET /api/stats/system-resources       # Recursos del sistema
GET /api/stats/alerts                 # Alertas activas
```

### ğŸ”§ Limpieza y Mantenimiento
- âœ… **FunciÃ³n** `cleanup_old_logs()` ejecutada diariamente
- âœ… **FunciÃ³n** `calculate_daily_metrics()` ejecutada cada hora
- âœ… **CompactaciÃ³n** de mÃ©tricas antiguas

## ğŸš€ InstalaciÃ³n

### ğŸ“‹ Prerequisitos
```bash
# Python 3.11+
python --version

# PostgreSQL corriendo en puerto 8070
# Base de datos ai_platform_stats creada
```

### ğŸ”§ ConfiguraciÃ³n Local
```bash
# 1. Instalar dependencias
cd stats/
pip install -r requirements.txt

# 2. Configurar variables de entorno (.env)
DB_HOST=localhost
DB_PORT=8070
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=ai_platform_stats

# ConfiguraciÃ³n de modelos
GEMMA_2B_PORT=8085
GEMMA_4B_PORT=8086
MISTRAL_7B_PORT=8088
FRAUD_API_PORT=8001
TEXTOSQL_API_PORT=8000

# 3. Ejecutar aplicaciÃ³n
python app.py
```

### ğŸ³ Docker (Recomendado)
```bash
# Construir imagen
docker build -t ai-platform-stats .

# Ejecutar contenedor
docker run -d \
  --name stats-api \
  -p 8003:8003 \
  --network ai_platform_network \
  -e DOCKER_ENV=true \
  ai-platform-stats
```

## ğŸ“¡ Endpoints Principales

### ğŸ  Health & Info
```bash
GET /                    # Info bÃ¡sica del servicio
GET /health             # Health check completo
GET /docs               # DocumentaciÃ³n Swagger
```

### ğŸ“Š Dashboard APIs
```bash
GET /api/stats/dashboard-summary
# Retorna: active_models, daily_queries, avg_response_time, etc.

GET /api/stats/models-status  
# Retorna: estado detallado de todos los modelos IA

GET /api/stats/functionality-performance
# Retorna: mÃ©tricas por funcionalidad (Ãºltimos 7 dÃ­as)

GET /api/stats/recent-errors
# Retorna: top errores (Ãºltimas 24 horas)

GET /api/stats/hourly-trends
# Retorna: tendencias por hora

GET /api/stats/system-resources?hours=24
# Retorna: uso de CPU, RAM, disco

GET /api/stats/alerts?resolved=false&severity=4
# Retorna: alertas activas filtradas
```

### ğŸ”§ AdministraciÃ³n
```bash
POST /api/admin/cleanup-logs
# Ejecuta limpieza de logs antiguos

POST /api/admin/calculate-metrics  
# Calcula mÃ©tricas diarias manualmente

POST /api/admin/refresh-models
# Refresca estado de modelos

POST /api/admin/resolve-alert/{alert_id}
# Resuelve una alerta especÃ­fica
```

### ğŸ“ˆ MÃ©tricas EspecÃ­ficas
```bash
GET /api/metrics/model/{model_name}
# MÃ©tricas de un modelo especÃ­fico

GET /api/metrics/functionality/{functionality}/history?days=7
# Historial de una funcionalidad
```

## ğŸ›ï¸ ConfiguraciÃ³n

### âš™ï¸ Variables de Entorno
```bash
# Servidor
HOST=0.0.0.0
PORT=8003
DEBUG=false

# Base de datos
DATABASE_URL=postgresql://user:pass@host:port/db
DB_HOST=localhost
DB_PORT=8070
DB_NAME=ai_platform_stats

# Umbrales de alertas
MODEL_TIMEOUT_THRESHOLD=30      # segundos
API_ERROR_RATE_THRESHOLD=10.0   # porcentaje  
MEMORY_USAGE_THRESHOLD=90.0     # porcentaje
CPU_USAGE_THRESHOLD=90.0        # porcentaje

# Intervalos de monitoreo
HEALTH_CHECK_INTERVAL=300       # 5 minutos
METRICS_COLLECTION_INTERVAL=60  # 1 minuto
ALERT_CHECK_INTERVAL=120        # 2 minutos

# RetenciÃ³n de datos
LOG_RETENTION_DAYS=30
```

### ğŸ”— IntegraciÃ³n con Otros Servicios

#### Para TextoSQL API
```python
from middleware import add_functionality_context, add_complexity_score, add_sql_execution_time

@app.post("/api/textosql/query")
async def process_query(request: Request, query: QueryRequest):
    # Agregar contexto
    add_functionality_context(request, "textosql", "gemma-2b")
    add_complexity_score(request, calculate_complexity(query.text))
    
    # Procesar query
    start_time = time.time()
    sql_result = await execute_sql(generated_sql)
    sql_time = time.time() - start_time
    
    # Agregar tiempo de ejecuciÃ³n SQL
    add_sql_execution_time(request, sql_time)
    
    return result
```

#### Para Fraud Detection API  
```python
from middleware import add_functionality_context, add_fraud_score

@app.post("/api/fraud/detect")
async def detect_fraud(request: Request, transaction: TransactionData):
    # Agregar contexto
    add_functionality_context(request, "fraud-detection", "fraud-model")
    
    # Procesar detecciÃ³n
    risk_score = await analyze_fraud(transaction)
    
    # Agregar score de riesgo
    add_fraud_score(request, risk_score)
    
    return {"risk_score": risk_score}
```

## ğŸ—„ï¸ Estructura de Base de Datos

### ğŸ“‹ Tablas Principales
- **`ai_models_metrics`**: Estado y performance de modelos IA
- **`functionality_metrics`**: MÃ©tricas agregadas por funcionalidad  
- **`api_performance_logs`**: Logs detallados de APIs
- **`accuracy_metrics`**: MÃ©tricas de precisiÃ³n y calidad
- **`system_resources`**: Uso de recursos del sistema
- **`database_metrics`**: MÃ©tricas de base de datos
- **`system_alerts`**: Alertas y eventos del sistema

### ğŸ” Vistas Optimizadas
- **`dashboard_summary`**: Resumen principal para dashboard
- **`functionality_performance`**: Performance por funcionalidad  
- **`models_status_detailed`**: Estado detallado de modelos
- **`top_errors_recent`**: Top errores recientes
- **`hourly_performance_trends`**: Tendencias por hora

## ğŸ” Monitoreo y Alertas

### ğŸš¨ Tipos de Alertas
1. **Modelos no responsivos** (CrÃ­tico)
2. **APIs con alta tasa de error** (Alto)  
3. **Uso de recursos crÃ­tico** (CrÃ­tico)
4. **Tiempos de respuesta lentos** (Medio)
5. **Errores consecutivos** (Alto)

### ğŸ“Š MÃ©tricas Monitoreadas
- âœ… **Response time** de modelos y APIs
- âœ… **Error rates** por endpoint
- âœ… **CPU, RAM, Disco** del sistema
- âœ… **Conexiones** de base de datos activas
- âœ… **Contenedores Docker** corriendo
- âœ… **Tokens procesados** por modelos LLM

## ğŸ³ Docker Compose Integration

```yaml
services:
  stats-api:
    build:
      context: ./stats
      dockerfile: Dockerfile
    container_name: stats-api
    restart: always
    ports:
      - "${STATS_PORT:-8003}:8003"
    environment:
      - DOCKER_ENV=true
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/ai_platform_stats
    depends_on:
      - postgres
    networks:
      - ai_platform_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

## ğŸ“ Logging y Debugging

### ğŸ“‹ Logs Estructurados
```bash
# Ver logs en tiempo real
docker logs -f stats-api

# Logs con nivel DEBUG
export LOG_LEVEL=DEBUG
python app.py
```

### ğŸ” Debugging Health Checks
```python
# Verificar manualmente un modelo
curl http://localhost:8003/api/admin/refresh-models

# Ver estado de modelo especÃ­fico  
curl http://localhost:8003/api/metrics/model/gemma-2b

# Ver alertas activas
curl http://localhost:8003/api/stats/alerts?resolved=false
```

## ğŸš€ Performance y Escalabilidad

- âœ… **Pool de conexiones** AsyncPG optimizado
- âœ… **Ãndices estratÃ©gicos** en todas las tablas  
- âœ… **Limpieza automÃ¡tica** de datos antiguos
- âœ… **MÃ©tricas agregadas** por hora/dÃ­a
- âœ… **Health checks paralelos** para modelos
- âœ… **Middleware asÃ­ncrono** sin bloqueos

---

**ğŸ¯ Sistema completo de observabilidad para la plataforma IBM AI Backend**

*Monitoreo automÃ¡tico, alertas proactivas y mÃ©tricas detalladas para mÃ¡xima visibilidad del sistema* ğŸš€
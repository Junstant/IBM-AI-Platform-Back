# Stats API

Sistema de m√©tricas y monitoreo para la plataforma AI.

## Caracter√≠sticas

- Logging autom√°tico de todas las requests
- Health checks de modelos LLM cada 5 minutos
- M√©tricas de performance por funcionalidad
- Sistema de alertas autom√°tico
- Dashboard con estad√≠sticas en tiempo real

## Endpoints

**Puerto**: `http://localhost:8003/docs`

- `GET /api/stats/dashboard-summary` - Resumen principal
- `GET /api/stats/models-status` - Estado de modelos LLM
- `GET /api/stats/functionality-performance` - Performance por API
- `GET /api/stats/recent-errors` - Errores recientes
- `GET /api/stats/hourly-trends` - Tendencias por hora
- `GET /api/stats/system-resources` - Recursos del sistema
GET /api/stats/alerts                 # Alertas activas
```

### üîß Limpieza y Mantenimiento
- ‚úÖ **Funci√≥n** `cleanup_old_logs()` ejecutada diariamente
- ‚úÖ **Funci√≥n** `calculate_daily_metrics()` ejecutada cada hora
- ‚úÖ **Compactaci√≥n** de m√©tricas antiguas

## üöÄ Instalaci√≥n

### üìã Prerequisitos
```bash
# Python 3.11+
python --version

# PostgreSQL corriendo en puerto 8070
# Base de datos ai_platform_stats creada
```

### üîß Configuraci√≥n Local
```bash
# 1. Instalar dependencias
cd stats/
pip install -r requirements.txt

# 2. Configurar variables de entorno (.env)
DB_HOST=localhost
DB_PORT=8070
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=ai_platform_stats

# Configuraci√≥n de modelos
GEMMA_2B_PORT=8085
GEMMA_4B_PORT=8086
MISTRAL_7B_PORT=8088
FRAUD_API_PORT=8001
TEXTOSQL_API_PORT=8000

# 3. Ejecutar aplicaci√≥n
python app.py
```

### üê≥ Docker (Recomendado)
```bash
# Construir imagen
docker build -t ai-platform-stats .

# Ejecutar contenedor
docker run -d \
  --name stats-api \
  -p 8003:8003 \
  --network ai_platform_network \
  -e DOCKER_ENV=true \
  ai-platform-stats
```

## üì° Endpoints Principales

### üè† Health & Info
```bash
GET /                    # Info b√°sica del servicio
GET /health             # Health check completo
GET /docs               # Documentaci√≥n Swagger
```

### üìä Dashboard APIs
```bash
GET /api/stats/dashboard-summary
# Retorna: active_models, daily_queries, avg_response_time, etc.

GET /api/stats/models-status  
# Retorna: estado detallado de todos los modelos IA

GET /api/stats/functionality-performance
# Retorna: m√©tricas por funcionalidad (√∫ltimos 7 d√≠as)

GET /api/stats/recent-errors
# Retorna: top errores (√∫ltimas 24 horas)

GET /api/stats/hourly-trends
# Retorna: tendencias por hora

GET /api/stats/system-resources?hours=24
# Retorna: uso de CPU, RAM, disco

GET /api/stats/alerts?resolved=false&severity=4
# Retorna: alertas activas filtradas
```

### üîß Administraci√≥n
```bash
POST /api/admin/cleanup-logs
# Ejecuta limpieza de logs antiguos

POST /api/admin/calculate-metrics  
# Calcula m√©tricas diarias manualmente

POST /api/admin/refresh-models
# Refresca estado de modelos

POST /api/admin/resolve-alert/{alert_id}
# Resuelve una alerta espec√≠fica
```

### üìà M√©tricas Espec√≠ficas
```bash
GET /api/metrics/model/{model_name}
# M√©tricas de un modelo espec√≠fico

GET /api/metrics/functionality/{functionality}/history?days=7
# Historial de una funcionalidad
```

## üéõÔ∏è Configuraci√≥n

### ‚öôÔ∏è Variables de Entorno
```bash
# Servidor
HOST=0.0.0.0
PORT=8003
DEBUG=false

# Base de datos
DATABASE_URL=postgresql://user:pass@host:port/db
DB_HOST=localhost
DB_PORT=8070
DB_NAME=ai_platform_stats

# Umbrales de alertas
MODEL_TIMEOUT_THRESHOLD=30      # segundos
API_ERROR_RATE_THRESHOLD=10.0   # porcentaje  
MEMORY_USAGE_THRESHOLD=90.0     # porcentaje
CPU_USAGE_THRESHOLD=90.0        # porcentaje

# Intervalos de monitoreo
HEALTH_CHECK_INTERVAL=300       # 5 minutos
METRICS_COLLECTION_INTERVAL=60  # 1 minuto
ALERT_CHECK_INTERVAL=120        # 2 minutos

# Retenci√≥n de datos
LOG_RETENTION_DAYS=30
```

### üîó Integraci√≥n con Otros Servicios

#### Para TextoSQL API
```python
from middleware import add_functionality_context, add_complexity_score, add_sql_execution_time

@app.post("/api/textosql/query")
async def process_query(request: Request, query: QueryRequest):
    # Agregar contexto
    add_functionality_context(request, "textosql", "gemma-2b")
    add_complexity_score(request, calculate_complexity(query.text))
    
    # Procesar query
    start_time = time.time()
    sql_result = await execute_sql(generated_sql)
    sql_time = time.time() - start_time
    
    # Agregar tiempo de ejecuci√≥n SQL
    add_sql_execution_time(request, sql_time)
    
    return result
```

#### Para Fraud Detection API  
```python
from middleware import add_functionality_context, add_fraud_score

@app.post("/api/fraud/detect")
async def detect_fraud(request: Request, transaction: TransactionData):
    # Agregar contexto
    add_functionality_context(request, "fraud-detection", "fraud-model")
    
    # Procesar detecci√≥n
    risk_score = await analyze_fraud(transaction)
    
    # Agregar score de riesgo
    add_fraud_score(request, risk_score)
    
    return {"risk_score": risk_score}
```

## üóÑÔ∏è Estructura de Base de Datos

### üìã Tablas Principales
- **`ai_models_metrics`**: Estado y performance de modelos IA
- **`functionality_metrics`**: M√©tricas agregadas por funcionalidad  
- **`api_performance_logs`**: Logs detallados de APIs
- **`accuracy_metrics`**: M√©tricas de precisi√≥n y calidad
- **`system_resources`**: Uso de recursos del sistema
- **`database_metrics`**: M√©tricas de base de datos
- **`system_alerts`**: Alertas y eventos del sistema

### üîç Vistas Optimizadas
- **`dashboard_summary`**: Resumen principal para dashboard
- **`functionality_performance`**: Performance por funcionalidad  
- **`models_status_detailed`**: Estado detallado de modelos
- **`top_errors_recent`**: Top errores recientes
- **`hourly_performance_trends`**: Tendencias por hora

## üîç Monitoreo y Alertas

### üö® Tipos de Alertas
1. **Modelos no responsivos** (Cr√≠tico)
2. **APIs con alta tasa de error** (Alto)  
3. **Uso de recursos cr√≠tico** (Cr√≠tico)
4. **Tiempos de respuesta lentos** (Medio)
5. **Errores consecutivos** (Alto)

### üìä M√©tricas Monitoreadas
- ‚úÖ **Response time** de modelos y APIs
- ‚úÖ **Error rates** por endpoint
- ‚úÖ **CPU, RAM, Disco** del sistema
- ‚úÖ **Conexiones** de base de datos activas
- ‚úÖ **Contenedores Docker** corriendo
- ‚úÖ **Tokens procesados** por modelos LLM

## üê≥ Docker Compose Integration

```yaml
services:
  stats-api:
    build:
      context: ./stats
      dockerfile: Dockerfile
    container_name: stats-api
    restart: always
    ports:
      - "${STATS_PORT:-8003}:8003"
    environment:
      - DOCKER_ENV=true
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@postgres:5432/ai_platform_stats
    depends_on:
      - postgres
    networks:
      - ai_platform_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

## üìù Logging y Debugging

### üìã Logs Estructurados
```bash
# Ver logs en tiempo real
docker logs -f stats-api

# Logs con nivel DEBUG
export LOG_LEVEL=DEBUG
python app.py
```

### üîç Debugging Health Checks
```python
# Verificar manualmente un modelo
curl http://localhost:8003/api/admin/refresh-models

# Ver estado de modelo espec√≠fico  
curl http://localhost:8003/api/metrics/model/gemma-2b

# Ver alertas activas
curl http://localhost:8003/api/stats/alerts?resolved=false
```

## üöÄ Performance y Escalabilidad

- ‚úÖ **Pool de conexiones** AsyncPG optimizado
- ‚úÖ **√çndices estrat√©gicos** en todas las tablas  
- ‚úÖ **Limpieza autom√°tica** de datos antiguos
- ‚úÖ **M√©tricas agregadas** por hora/d√≠a
- ‚úÖ **Health checks paralelos** para modelos
- ‚úÖ **Middleware as√≠ncrono** sin bloqueos

---

**üéØ Sistema completo de observabilidad para la plataforma IBM AI Backend**

*Monitoreo autom√°tico, alertas proactivas y m√©tricas detalladas para m√°xima visibilidad del sistema* üöÄ
"""
Script de pruebas para el sistema de estad√≠sticas AI Platform
"""

import asyncio
import time
import json
import aiohttp
import logging
from datetime import datetime

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StatsAPITester:
    """Clase para probar la API de estad√≠sticas"""
    
    def __init__(self, base_url: str = "http://localhost:8003"):
        self.base_url = base_url
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def test_health_check(self):
        """Probar health check"""
        logger.info("üîç Probando health check...")
        
        try:
            async with self.session.get(f"{self.base_url}/health") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Health check OK: {data['status']}")
                    return True
                else:
                    logger.error(f"‚ùå Health check failed: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"‚ùå Error en health check: {e}")
            return False
    
    async def test_dashboard_summary(self):
        """Probar endpoint de resumen del dashboard"""
        logger.info("üìä Probando dashboard summary...")
        
        try:
            async with self.session.get(f"{self.base_url}/api/stats/dashboard-summary") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info("‚úÖ Dashboard summary OK:")
                    logger.info(f"   Modelos activos: {data.get('active_models', 0)}")
                    logger.info(f"   Consultas diarias: {data.get('daily_queries', 0)}")
                    logger.info(f"   Tiempo promedio: {data.get('avg_response_time', 0):.3f}s")
                    return True
                else:
                    logger.error(f"‚ùå Dashboard summary failed: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"‚ùå Error en dashboard summary: {e}")
            return False
    
    async def test_models_status(self):
        """Probar endpoint de estado de modelos"""
        logger.info("ü§ñ Probando models status...")
        
        try:
            async with self.session.get(f"{self.base_url}/api/stats/models-status") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Models status OK: {len(data)} modelos encontrados")
                    
                    for model in data[:3]:  # Mostrar solo los primeros 3
                        logger.info(f"   {model['model_name']}: {model['status']} "
                                  f"({model['success_rate']:.1f}% success)")
                    return True
                else:
                    logger.error(f"‚ùå Models status failed: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"‚ùå Error en models status: {e}")
            return False
    
    async def test_functionality_performance(self):
        """Probar endpoint de performance por funcionalidad"""
        logger.info("‚ö° Probando functionality performance...")
        
        try:
            async with self.session.get(f"{self.base_url}/api/stats/functionality-performance") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Functionality performance OK: {len(data)} funcionalidades")
                    
                    for func in data:
                        logger.info(f"   {func['functionality']}: {func['total_queries']} queries "
                                  f"({func['success_rate']:.1f}% success)")
                    return True
                else:
                    logger.error(f"‚ùå Functionality performance failed: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"‚ùå Error en functionality performance: {e}")
            return False
    
    async def test_system_resources(self):
        """Probar endpoint de recursos del sistema"""
        logger.info("üíª Probando system resources...")
        
        try:
            async with self.session.get(f"{self.base_url}/api/stats/system-resources?hours=1") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ System resources OK: {len(data)} registros")
                    
                    if data:
                        latest = data[0]
                        logger.info(f"   CPU: {latest.get('cpu_usage_percent', 0):.1f}%")
                        logger.info(f"   RAM: {latest.get('memory_usage_percent', 0):.1f}%")
                        logger.info(f"   Disco: {latest.get('disk_usage_percent', 0):.1f}%")
                    return True
                else:
                    logger.error(f"‚ùå System resources failed: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"‚ùå Error en system resources: {e}")
            return False
    
    async def test_alerts(self):
        """Probar endpoint de alertas"""
        logger.info("üö® Probando alerts...")
        
        try:
            async with self.session.get(f"{self.base_url}/api/stats/alerts?resolved=false") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Alerts OK: {len(data)} alertas activas")
                    
                    critical_alerts = [a for a in data if a.get('severity', 0) >= 4]
                    if critical_alerts:
                        logger.warning(f"‚ö†Ô∏è  {len(critical_alerts)} alertas cr√≠ticas encontradas")
                        for alert in critical_alerts[:2]:
                            logger.warning(f"   {alert['title']}")
                    return True
                else:
                    logger.error(f"‚ùå Alerts failed: {response.status}")
                    return False
        except Exception as e:
            logger.error(f"‚ùå Error en alerts: {e}")
            return False
    
    async def test_admin_functions(self):
        """Probar funciones administrativas"""
        logger.info("üîß Probando admin functions...")
        
        try:
            # Calcular m√©tricas manualmente
            async with self.session.post(f"{self.base_url}/api/admin/calculate-metrics") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Calculate metrics OK: {data.get('message')}")
                else:
                    logger.warning(f"‚ö†Ô∏è  Calculate metrics warning: {response.status}")
            
            # Refrescar modelos
            async with self.session.post(f"{self.base_url}/api/admin/refresh-models") as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Refresh models OK: {data.get('message')}")
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è  Refresh models warning: {response.status}")
                    return False
                    
        except Exception as e:
            logger.error(f"‚ùå Error en admin functions: {e}")
            return False
    
    async def simulate_api_calls(self, count: int = 10):
        """Simular llamadas API para generar m√©tricas"""
        logger.info(f"üéØ Simulando {count} llamadas API...")
        
        endpoints = [
            "/",
            "/health",
            "/api/stats/dashboard-summary",
            "/api/stats/models-status",
            "/api/stats/alerts"
        ]
        
        success_count = 0
        
        for i in range(count):
            endpoint = endpoints[i % len(endpoints)]
            try:
                async with self.session.get(f"{self.base_url}{endpoint}") as response:
                    if response.status < 400:
                        success_count += 1
                
                # Peque√±a pausa entre requests
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.debug(f"Error en simulaci√≥n: {e}")
        
        logger.info(f"‚úÖ Simulaci√≥n completada: {success_count}/{count} requests exitosas")
        return success_count

async def run_tests():
    """Ejecutar todas las pruebas"""
    logger.info("üöÄ Iniciando pruebas del sistema de estad√≠sticas AI Platform")
    logger.info("=" * 60)
    
    start_time = time.time()
    passed_tests = 0
    total_tests = 0
    
    async with StatsAPITester() as tester:
        # Lista de pruebas
        tests = [
            ("Health Check", tester.test_health_check),
            ("Dashboard Summary", tester.test_dashboard_summary),
            ("Models Status", tester.test_models_status),
            ("Functionality Performance", tester.test_functionality_performance),
            ("System Resources", tester.test_system_resources),
            ("Alerts", tester.test_alerts),
            ("Admin Functions", tester.test_admin_functions),
        ]
        
        # Ejecutar pruebas
        for test_name, test_func in tests:
            total_tests += 1
            logger.info(f"\n--- {test_name} ---")
            
            try:
                if await test_func():
                    passed_tests += 1
            except Exception as e:
                logger.error(f"‚ùå {test_name} fall√≥ con excepci√≥n: {e}")
        
        # Simular tr√°fico
        logger.info(f"\n--- Simulaci√≥n de Tr√°fico ---")
        await tester.simulate_api_calls(20)
        
        # Esperar un poco para que se procesen las m√©tricas
        logger.info("‚è≥ Esperando procesamiento de m√©tricas...")
        await asyncio.sleep(2)
        
        # Verificar m√©tricas despu√©s de la simulaci√≥n
        logger.info(f"\n--- Verificaci√≥n Post-Simulaci√≥n ---")
        await tester.test_dashboard_summary()
    
    # Resumen final
    execution_time = time.time() - start_time
    logger.info("=" * 60)
    logger.info("üìä RESUMEN DE PRUEBAS")
    logger.info(f"Pruebas pasadas: {passed_tests}/{total_tests}")
    logger.info(f"Tiempo de ejecuci√≥n: {execution_time:.2f} segundos")
    
    if passed_tests == total_tests:
        logger.info("üéâ ¬°Todas las pruebas pasaron exitosamente!")
        return True
    else:
        logger.warning(f"‚ö†Ô∏è  {total_tests - passed_tests} pruebas fallaron")
        return False

if __name__ == "__main__":
    # Ejecutar pruebas
    try:
        success = asyncio.run(run_tests())
        exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("üõë Pruebas interrumpidas por el usuario")
        exit(1)
    except Exception as e:
        logger.error(f"‚ùå Error ejecutando pruebas: {e}")
        exit(1)